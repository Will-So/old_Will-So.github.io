<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Analytical Sense</title><link href="http://analyticalsen.se/" rel="alternate"></link><link href="http://analyticalsen.se/feeds/will-sorenson.atom.xml" rel="self"></link><id>http://analyticalsen.se/</id><updated>2016-01-18T00:00:00+01:00</updated><entry><title>Dealing With Outliers: The Concepts</title><link href="http://analyticalsen.se/blog/Dealing_Wi.html" rel="alternate"></link><published>2016-01-18T00:00:00+01:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2016-01-18:blog/Dealing_Wi.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Making-Models-Robust-to-Outliers"&gt;Making Models Robust to Outliers&lt;a class="anchor-link" href="#Making-Models-Robust-to-Outliers"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One of the more difficult part of making predictive models is making sure that our model is robust to outliers. Fitting data strongly to outliers tends to give us bad predictive results. There are two solution that will work well in most cases and the are a few other methods worth considering when the first two either fail or are impracticle.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Use-a-robust-loss-function"&gt;Use a robust loss function&lt;a class="anchor-link" href="#Use-a-robust-loss-function"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Mean squared error (MSE) and thus root mean squared error (RMSE) are very sensitive to outliers (&lt;a href="#footnotes"&gt;1&lt;/a&gt;). Sometimes, this is desirable where we want to punish an error of 20 much more than an error of 5. (400 vs 25). This is not desirable when we are trying to avoid outliers from having an exaggerated effect on our model.&lt;/p&gt;
&lt;p&gt;Mean Absolute Error is somewhat less sensitive to outliers because it does not square the errors. It is not "robust" to outliers but it represents a middle ground between traditional loss functions and methods discussed below.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="The-Huber-Loss-function"&gt;The Huber Loss function&lt;a class="anchor-link" href="#The-Huber-Loss-function"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One of the better loss functions to choose is the Huber Loss function. It is &lt;a href="http://en.wikipedia.org/wiki/Huber_loss"&gt;defined&lt;/a&gt; as:&lt;/p&gt;
$$L_\delta (a) = \begin{cases}
 \frac{1}{2}{a^2}                   &amp; \text{for } |a| \le \delta, \\
 \delta (|a| - \frac{1}{2}\delta), &amp; \text{otherwise.}
\end{cases}$$&lt;p&gt;This has the effect of combining Squared Errors and Absolute Errors. For $|a| \le \delta$, the error function represents the RMSE. For $|a| \ge \delta$, the error function represents Mean Absolute Errors.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Winsorizing-the-Data"&gt;Winsorizing the Data&lt;a class="anchor-link" href="#Winsorizing-the-Data"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Winsorizing the data provides the same results as the Huber Loss Function when $\delta$ in the huber loss function is equal to the point at which the value is winsorized. This has a large disadvantage compared to the Huber Loss Function in that we are making changes to the dataset. That leaves us with a choice between making two copies of the data (one winsorized and non-winsorized) or discarding some information that may come in useful in future analysis. The former may not be practical for very large datasets.&lt;/p&gt;
&lt;p&gt;An advantage of winsorizing data is that it makes it easy to visualize that data in a meaningful way.&lt;/p&gt;
&lt;p&gt;Pandas has &lt;code&gt;pd.clip()&lt;/code&gt; for this capability which makes it easy to use.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="http://upload.wikimedia.org/wikipedia/commons/c/c1/RhoFunctions.png" alt=""&gt;
Source: Wikipedia&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Discarding-Outliers"&gt;Discarding Outliers&lt;a class="anchor-link" href="#Discarding-Outliers"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Most data munging has outliers that are almost certainly products of measurement errors or very rare anomalies.&lt;/p&gt;
&lt;p&gt;Some examples of this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Demographic surveys where someone has 17 PhDs&lt;/li&gt;
&lt;li&gt;Someone borrowing from lending club with a yearly income of 7M.&lt;/li&gt;
&lt;li&gt;A stock transaction with a trade time before stock markets opened.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Even in the event some of those observations were accurately measures (quite unlikely), they almost surely lack external validity so will only hurt the performance of our model unless we delete them.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Use-a-Model-that-is-Robust-to-Standard-Errors"&gt;Use a Model that is Robust to Standard Errors&lt;a class="anchor-link" href="#Use-a-Model-that-is-Robust-to-Standard-Errors"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Support Vector Machines in particular tend to not consider outliers during training. Gradient Boosting, and Random Forests also have nice properties that make it difficult (but not impossible) to overfit a training dataset.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="A-Bad-method:-Log-transforms"&gt;A Bad method: Log transforms&lt;a class="anchor-link" href="#A-Bad-method:-Log-transforms"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Log transforms are often mooted as a good way to make outliers stand out less. When we use a log transform we are allowing the outliers to dictate how we describe &lt;strong&gt;all of our observations&lt;/strong&gt;. This is just the opposite of using a robust measure.&lt;/p&gt;
&lt;p&gt;This is not to say that log transforms should not be used. There are many situations when log transforms should be used &lt;strong&gt;due to the behavior of all the observations&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;When the errors have an extreme positvely skewed distribution. We then use the &lt;a href="http://en.wikipedia.org/wiki/Power_transform#Box.E2.80.93Cox_transformation"&gt;Box-Cox&lt;/a&gt;. This allows us to improve the validity of the Pearson Correlation coefficient, stabalize variance, and in general make traditional descriptive statistics more meaningful.&lt;/li&gt;
&lt;li&gt;When the relationship being investigates is close to exponential.&lt;/li&gt;
&lt;li&gt;When you want to represent a model that explains the explanatory variables' influence in terms of percentages (relative values) rather than absolute differences. &lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="-Footnotes"&gt;&lt;a id="footnotes" /&gt; Footnotes&lt;a class="anchor-link" href="#-Footnotes"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;[1]: This is easy to see from the mathematical definition of MSE: $1/n \sum( \hat Y_i- Y_i)^2$. Since the distance between the sample mean and the datapoint is squared, it exaggerates the influence of outliers.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stats.stackexchange.com/questions/48267/mean-absolute-error-or-root-mean-squared-error"&gt;http://stats.stackexchange.com/questions/48267/mean-absolute-error-or-root-mean-squared-error&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://projecteuclid.org/download/pdf_1/euclid.aoms/1177703732"&gt;http://projecteuclid.org/download/pdf_1/euclid.aoms/1177703732&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="ETL"></category></entry><entry><title>Starting a Successful Restaurant</title><link href="http://analyticalsen.se/blog/Starting_a.html" rel="alternate"></link><published>2015-12-16T00:00:00+01:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-12-16:blog/Starting_a.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Founding a successful restaurant is hard. 60% fail in 3 years. This pales in comparison to hotel chains that average a 7% failure rate over 10 years. Growing up, my uncle Jim struggled with his restaurant for 3 years before he finally admitted defeat.&lt;/p&gt;
&lt;p&gt;Can we use Data to improve the chances of starting a successful restaurant? This month, I decided to find out.&lt;/p&gt;
&lt;p&gt;The goal for this project is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Find the location that maximizes their chances for success&lt;/li&gt;
&lt;li&gt;Choose the ameneties and other features that maximize their chance of success &lt;/li&gt;
&lt;li&gt;Predict their chances of success given their prospective location and amenities. &lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="1.-Getting-the-Data"&gt;1. Getting the Data&lt;a class="anchor-link" href="#1.-Getting-the-Data"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Thanks to the Yelp Challenge, the data I needed was easy to get and the data was shockingly consistent. There were next to no anomalous data points.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="2.-Defining-Success"&gt;2. Defining Success&lt;a class="anchor-link" href="#2.-Defining-Success"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One challenge of this project is defining success. I don't have the profits and losses of individual restaurants so I need to infer success based on observable data we have. I define the function as $F(Rating, \frac{Number\_Reviews}{Month}, Time)$. The actual form of this function is somewhat complicated and can be seen in the &lt;code&gt;measuring_success&lt;/code&gt; notebook. The top 25% of Yelp Restaurants according to this function were labeled as successful.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="3.-Feature-Engineering"&gt;3. Feature Engineering&lt;a class="anchor-link" href="#3.-Feature-Engineering"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Location-Location-Location"&gt;Location Location Location&lt;a class="anchor-link" href="#Location-Location-Location"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One of the key features in my model is the success of businesses in a nearby location. I use a K-d tree to efficiently find the 10 nearest businesses to a given point and then average those success values.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Latent-Topics"&gt;Latent Topics&lt;a class="anchor-link" href="#Latent-Topics"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I use latent topics with Latent Dirichlet allocation to make features. This combination of using an unsupervised learning technique to generate features for a supervised model can provide powerful insights.&lt;/p&gt;
&lt;p&gt;Unfortunately, latent topics in this case were simply not predictive of success. This is despite coherent categories.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Explicit-Topics"&gt;Explicit Topics&lt;a class="anchor-link" href="#Explicit-Topics"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Explicit topics (i.e., categories) perform much better than LDA topics. They end up predicting nearly as well as location in the aggregate.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="4.-Modeling,-Evaluating,-and-Refining"&gt;4. Modeling, Evaluating, and Refining&lt;a class="anchor-link" href="#4.-Modeling,-Evaluating,-and-Refining"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I tried a number of different classifiers at first. Random Forests performed the best but there was still something wrong with it. It had way too many false positives. If my model predicted that the restaurant would be successful, the restaurant would only actually be successful 50% of the time. This is much better than change (25%) but I thought we can do better.&lt;/p&gt;
&lt;p&gt;I adjusted the classifer to have balanced classes in each tree and this decreased the false positive substantially. Now my model had a true positive rate of 66%. This represents more than a 150% increase in the chanse of being successful.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3668.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The most important features:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3669.png" alt=""&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="5.-Building-the-Web-App"&gt;5. Building the Web App&lt;a class="anchor-link" href="#5.-Building-the-Web-App"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Since most people who want to start restaurants tend not to be very technically savy, I decided to build a web app that allows people to easily use the model I built. Building the app was extremely straightfoward thanks to the awesomeness of Flask.&lt;/p&gt;
&lt;p&gt;This is a screenshot of the app I built:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3665.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The user workflow is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;User picks city. Map pans to city.&lt;/li&gt;
&lt;li&gt;User Picks the type of restaurant&lt;/li&gt;
&lt;li&gt;User clicks on the map to specify a location&lt;/li&gt;
&lt;li&gt;App returns probability of success. &lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Conclusion"&gt;Conclusion&lt;a class="anchor-link" href="#Conclusion"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Using data to inform our decisions when founding a new business can be extremely valuable.&lt;/p&gt;
&lt;p&gt;This project also shows how valuable a good frontend can be for communicating insights in data. Without a good interface it would be difficult for people to make use of this data.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Threats-to-Model-Validity"&gt;Threats to Model Validity&lt;a class="anchor-link" href="#Threats-to-Model-Validity"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;Maturation: The test dataset that we evaluated accuracy on only has currently existing companies. It could be the case that past patterns of success are no longer predictive. &lt;/li&gt;
&lt;li&gt;Saturation: My model does not consider the potential of saturation. If we have too many sushi places right next to eachother, this can cause problems for profitability. Businesses being close to eachother is a good strategy to a point&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="The-Next-Iteration"&gt;The Next Iteration&lt;a class="anchor-link" href="#The-Next-Iteration"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;Add a heat map&lt;/li&gt;
&lt;li&gt;The app is currently not hosted anywhere. I hope to deploy it in the near future so others can make use of it.&lt;/li&gt;
&lt;li&gt;Add NLP features based on the reviews of the restaurant. &lt;/li&gt;
&lt;li&gt;Generalize to other businesses.&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="DS"></category><category term="ML"></category></entry><entry><title>Predicting Lending Club Defaults for Fun and Profit</title><link href="http://analyticalsen.se/blog/Predicting.html" rel="alternate"></link><published>2015-11-25T00:00:00+01:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-11-25:blog/Predicting.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One of my latest projects has beenPredicts the default rate of loans and automatically order the model's favorite currently available loans. Likely to increase ROI from 7.5% (Lending Club Average) to 13.5%. This project identifies investment stratagies that fit custom investment profiles. The user specifies the amount of capital she is willing to invest and either her desired expected return or her maximum risk tolerance.&lt;/p&gt;
&lt;p&gt;Key Features:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Choosing the model's favorite loans (top 20%) leads to an expected ROI of 13.5%&lt;/li&gt;
&lt;li&gt;Provides a web app to view the currently available loans with their predicted ROI and default probability. &lt;/li&gt;
&lt;li&gt;Use the lending club API to order the model's favorite loans automatically. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An Example of viewing currently available loans: 
&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3587.png" alt=""&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The github repository can be found &lt;a href="https://github.com/Will-So/Lending_Club"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Some-Descriptive-Statistics"&gt;Some Descriptive Statistics&lt;a class="anchor-link" href="#Some-Descriptive-Statistics"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;FICO scores do an excellent job predicting the default rate of P2P borrowers:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3594.png" alt="" style="height: 400px;vertical-align: left"/&gt;&lt;/p&gt;
&lt;p&gt;People with incomes $&lt;70k$ are more likely to default than richer borrowers:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3595.png" alt="" style="height: 400px;align: left"/&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Those who pay a very large percentage of their income to debt are more likely to default:
&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3596.png" alt="" style="height: 400px;"/&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Model-Selection"&gt;Model Selection&lt;a class="anchor-link" href="#Model-Selection"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I tried a number of different machine learning models for this project. Of them, Random Forests ended up performing the best. Details can be found in &lt;code&gt;modeling.ipynb&lt;/code&gt; and &lt;code&gt;modeling.ipynb II&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Feature-Engineering"&gt;Feature Engineering&lt;a class="anchor-link" href="#Feature-Engineering"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I tried a few custom-made features in my model. Notably, the ratio of total debt payments (lending club and other outstanding debt) to income was my second best feature.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3589.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;It is somewhat surprising that this model performs so well because it does not seem particurlaly important in the &lt;em&gt;Descriptive Statistics&lt;/em&gt; section.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Results"&gt;Results&lt;a class="anchor-link" href="#Results"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;If we pick my model's favorite 25% of loans, our default rate will be half that of similarly-graded notes. This represents an increase from 9% (ROI for C-G notes) to 13.5%.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Turning-our-Results-into-a-Product"&gt;Turning our Results into a Product&lt;a class="anchor-link" href="#Turning-our-Results-into-a-Product"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I made a very simple web-app to display the currently available notes and their expected ROI and default probability.&lt;/p&gt;
&lt;p&gt;I also made a script that will automatically order the best currently-available notes in order of expected ROI. I then told cron to run it 4x a day (when the notes are available). That way I an investment strategy that requires 0 effort from this day forward.&lt;/p&gt;
&lt;p&gt;Both of these can be found in the &lt;code&gt;app&lt;/code&gt; directory.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="The-Next-Iteration"&gt;The Next Iteration&lt;a class="anchor-link" href="#The-Next-Iteration"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;Make the Web App much better&lt;ul&gt;
&lt;li&gt;Integrate with Tableau Dashboard&lt;/li&gt;
&lt;li&gt;Try some more ML models to see what the best results will be. Especially gradienting boosting.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clean up the HTML files so that they are easier to read. &lt;/li&gt;
&lt;li&gt;Try some new ML Models&lt;ul&gt;
&lt;li&gt;Gradient Boosting Machines&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Allow multiprofile support&lt;ul&gt;
&lt;li&gt;A lot of LC power users have multiple accounts. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Make more tests&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="DS"></category></entry><entry><title>Everything You Need to Know to Use Random Forests</title><link href="http://analyticalsen.se/blog/Everything.html" rel="alternate"></link><published>2015-11-16T00:00:00+01:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-11-16:blog/Everything.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Random Forests are an increasingly popular machine learning algorithim. They perform well in a wide variety of learning and prediction problems despite being exceedingly easy to implement. Random forests can be used for both classification and regression problems.&lt;/p&gt;
&lt;p&gt;This post describes the intuition of how Random Forests work as well as its. advantages and disadvantages.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Intuition-for-How-Random-Forests-Work"&gt;Intuition for How Random Forests Work&lt;a class="anchor-link" href="#Intuition-for-How-Random-Forests-Work"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;At a high level, the algorithim usually works as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Randomly sample $N$ observations from the training set at random with replacement [1]&lt;/li&gt;
&lt;li&gt;Train a decision tree using $N$ and $\sqrt{num\_features}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Repeat (1) and (2) B times, where B is the number of trees (also called bags). Depending on the nature of data, the ideal number of trees ranging from 100 to several thousand.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="http://image.slidesharecdn.com/janvitekdistributedrandomforest5-2-2013-130504133205-phpapp02/95/jan-vitek-distributedrandomforest522013-8-638.jpg?cb=1367674437" alt=""&gt;
&lt;a href="http://www.slideshare.net/0xdata/jan-vitek-distributedrandomforest522013"&gt;Source: Jan Vitek, Perdue&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Main-Advantages"&gt;Main Advantages&lt;a class="anchor-link" href="#Main-Advantages"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Embarrassingly-Parallel"&gt;Embarrassingly Parallel&lt;a class="anchor-link" href="#Embarrassingly-Parallel"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;SKlearn will allow you to use all the cores in your computer to train multiple trees at the same time. The algorithim is also available in Spark. This is because all random forests are trained independently of eachother.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Resistant-to-Overfitting"&gt;Resistant to Overfitting&lt;a class="anchor-link" href="#Resistant-to-Overfitting"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The only way to overfit the model is to have trees that have too many branches. Increasing the number of trees does not increase the risk of overfitting. Instead an increasing number of trees tends to decrease the amount of overfitting&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="No-Need-for-Cross-Validation"&gt;No Need for Cross Validation&lt;a class="anchor-link" href="#No-Need-for-Cross-Validation"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We can also avoid cross-validation by using the &lt;em&gt;out of bag score&lt;/em&gt;. This is available as an argument in Spark and Sklearn and provides nearly identical results to N-fold cross-validation.[2]&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Other-Advantages"&gt;Other Advantages&lt;a class="anchor-link" href="#Other-Advantages"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Most implementations make it trivial to find feature importance&lt;/li&gt;
&lt;li&gt;It is very easy to Tune&lt;/li&gt;
&lt;li&gt;Random Forests excel with highly non-linear relationships in the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Main-Disadvantages"&gt;Main Disadvantages&lt;a class="anchor-link" href="#Main-Disadvantages"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Can-perform-worse-than-Gradient-Boost"&gt;Can perform worse than Gradient Boost&lt;a class="anchor-link" href="#Can-perform-worse-than-Gradient-Boost"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Gradient Boosted Machines tend to perform better under both of the following conditions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We correctly tune the relatively complicated hyperparamters of GBM. &lt;/li&gt;
&lt;li&gt;Either 1) your data fits in ram (for sklearn) or 2) your problem is not a multiclass classification problem (for Spark).&lt;/li&gt;
&lt;li&gt;(My understanding, not certain) Non-linear relationships &lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Slow-to-Predict"&gt;Slow to Predict&lt;a class="anchor-link" href="#Slow-to-Predict"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Since predicting a new observation requires running the observation through every tree, Random Forests will often perform too poorly for real-time prediction.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Doesn't-behave-well-for-very-sparse-feature-sets"&gt;Doesn't behave well for very sparse feature sets&lt;a class="anchor-link" href="#Doesn't-behave-well-for-very-sparse-feature-sets"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this case, SVM and Naive Bayes tend to perform better than Random Forests. One of the reasons for this is because each tree only has access to $\sqrt{n}$ features by default. If very few features are of any importance, most trees will miss important features.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Using-it-in-sklearn"&gt;Using it in sklearn&lt;a class="anchor-link" href="#Using-it-in-sklearn"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Below is an example of using a Random Forest with 50 trees:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model_rf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;oob_score&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2143&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_samples_split&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fitted_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The &lt;code&gt;oob_score&lt;/code&gt; argument tells the classifier to return our out of sample (bag) error estimates. The &lt;code&gt;min_samples_split=50&lt;/code&gt; argument tells the classifer to only create another branch of the tree if the current branch has more than 50 observations. &lt;code&gt;n_jobs=-1&lt;/code&gt; tells SKlearn to use all the cores on my machine.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Using-it-in-Spark"&gt;Using it in Spark&lt;a class="anchor-link" href="#Using-it-in-Spark"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;An example of using Random Forests in Spark can be found &lt;a href="https://spark.apache.org/docs/latest/mllib-ensembles.html"&gt;here&lt;/a&gt;. Here is the same example as in SKlearn:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Practical-tips"&gt;Practical tips&lt;a class="anchor-link" href="#Practical-tips"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;A good way to prevent overfitting is to set a relatively high tree-splitting threshhold. This is the &lt;code&gt;min_samples_split&lt;/code&gt; argument in SKLearn. &lt;/li&gt;
&lt;li&gt;We can easily check if we are overfitting by looking at the out of bag error. &lt;/li&gt;
&lt;li&gt;More trees are always better than fewer. The returns start to dominish quickly. 
  &lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3580.png" width="300"/&gt;&lt;ul&gt;
&lt;li&gt;Source &lt;a href="http://www.isip.piconepress.com/projects/dpm_inference/html/performance.html"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Having trees that are too deep can lead to overfitting. This can be avoided by increasing the number of trees. &lt;/li&gt;
&lt;li&gt;The default number of features ($\sqrt{n}$) is usually a sufficiently good value. &lt;/li&gt;
&lt;li&gt;After picking the best Random Forest with your out of bag errors, &lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Footnotes"&gt;Footnotes&lt;a class="anchor-link" href="#Footnotes"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;[1]: This means that the sample size will be the same as the training set size but the composition of the sample will be different because it is being sampled with replacement.&lt;/p&gt;
&lt;p&gt;[2]: This works by looking at the errors of the trees where the relevant observation $(X_i, y_i)$ did not occur.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning. Vol. 1. Springer, Berlin: Springer series in statistics, 2001.
APA    &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/0xdata/jan-vitek-distributedrandomforest522013"&gt;http://www.slideshare.net/0xdata/jan-vitek-distributedrandomforest522013&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/ensemble.html"&gt;http://scikit-learn.org/stable/modules/ensemble.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://download.springer.com/static/pdf/639/art%253A10.1023%252FA%253A1010933404324.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Farticle%2F10.1023%2FA%3A1010933404324&amp;amp;token2=exp=1447688130~acl=%2Fstatic%2Fpdf%2F639%2Fart%25253A10.1023%25252FA%25253A1010933404324.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Farticle%252F10.1023%252FA%253A1010933404324*~hmac=3b7a5a59b9ee6c2c4c500ef943cd2e0725e74621ba10977e4b51c8989b1819c7"&gt;Random Forests by Leo Breiman&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="ML"></category></entry><entry><title>Jupyter on the Cloud -- A How-To</title><link href="http://analyticalsen.se/blog/Jupyter_on.html" rel="alternate"></link><published>2015-11-16T00:00:00+01:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-11-16:blog/Jupyter_on.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Using the Jupyter Notebook with an EC2 instance allows us to analyze data of a size that would be difficult or impossible to do on our local machines. The most powerful (from a memory perspective) EC2 instance has 244GB of Ram and 32 cores and often costs only 50 cents/hr.&lt;/p&gt;
&lt;p&gt;This tutorial explains:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to Set up the Jupyter Notebook on an EC2 instance so we can use it from a web browser.&lt;/li&gt;
&lt;li&gt;How to keep the notebook running even if the SSH session closes.&lt;/li&gt;
&lt;li&gt;A workflow for dealing with spot instances. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This post assumes you are already familiar with the basics of EC2. You should know how to start an instance and SSH into it.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Step-1:-Setting-up-your-EC2-Instance"&gt;Step 1: Setting up your EC2 Instance&lt;a class="anchor-link" href="#Step-1:-Setting-up-your-EC2-Instance"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;Go to the EC2 Management Console and select launch instances&lt;/li&gt;
&lt;li&gt;Choose which AMI you want to use. I recommend Ubuntu. There might be some minor differences if you choose something else. [2]&lt;/li&gt;
&lt;li&gt;Select which type of instance you want and change any additional settings&lt;/li&gt;
&lt;li&gt;In the security group page, enable HTTPS and Port 9999. Port 9999 is the port we will be accessing the notebook from:
&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3570.png" alt=""&gt;&lt;/li&gt;
&lt;li&gt;Connect to your EC2 Instance with SSH&lt;/li&gt;
&lt;li&gt;Install all the software you need including the Notebook[3]&lt;ul&gt;
&lt;li&gt;The link to install conda can be found &lt;a href="https://www.continuum.io/downloads"&gt;here&lt;/a&gt;. Just copy the link address for linux and then use &lt;code&gt;wget link&lt;/code&gt; on your remote host to download it. Just follow the directions on the page. The installation will ask whether to append the conda environment to the Python path. Type in &lt;code&gt;yes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;After installing, you need to reload &lt;code&gt;.bashrc&lt;/code&gt; (type &lt;code&gt;. .bashrc&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Step-2:-Configuring-the-Notebook-Server"&gt;Step 2: Configuring the Notebook Server&lt;a class="anchor-link" href="#Step-2:-Configuring-the-Notebook-Server"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The Jupyter Documentation provides an excellent walkthrough on configuring the server &lt;a href="http://jupyter-notebook.readthedocs.org/en/latest/public_server.html"&gt;here&lt;/a&gt;. The tl;dr is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In the terminal type: &lt;code&gt;jupyter notebook --generate-config&lt;/code&gt; in order to generate the configuration file.&lt;/li&gt;
&lt;li&gt;In IPython type in &lt;code&gt;from notebook.auth import passwd; passwd()&lt;/code&gt; and then enter in the password you want to use to access the notebook. Remember the password and copy the hash you get back. &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Generate an SSL certificate using the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout mycert.key -out mycert.pem&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open the configuration file (&lt;code&gt;~/.jupyter/jupyter_notebook_config.py&lt;/code&gt; by default) you made with your favorite text editor and copy in the hash generated from passwd():&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_config&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NotebookApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;u&amp;#39;sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NotebookApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;*&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NotebookApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open_browser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NotebookApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;port&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;9999&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NotebookApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certfile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;u&amp;#39;/home/ubuntu/mycert.pem&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NotebookApp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keyfile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;u&amp;#39;/home/ubuntu/mycert.key&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In &lt;code&gt;.bashrc&lt;/code&gt; make the following alias:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;alias jupyter='nohup jupyter notebook &amp;amp;'&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then reload &lt;code&gt;.bashrc&lt;/code&gt; again. This also makes your jupyter session persistent. It will not stop running just because the ssh session is closed.&lt;/p&gt;
&lt;p&gt;Now you can type &lt;code&gt;jupyter&lt;/code&gt; in the terminal and the server should run. Then browse to &lt;a href="https://ip_address:9999"&gt;https://ip_address:9999&lt;/a&gt; and login with the password you entered:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3574.png" width="800"/&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Protecting-your-data-while-using-Spot-Instances"&gt;Protecting your data while using Spot Instances&lt;a class="anchor-link" href="#Protecting-your-data-while-using-Spot-Instances"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Spot instances are much cheaper than on-demand instances. They downside is that you can be kicked off your instance if the amount of capacity of the Spot Instance gets too high.&lt;/p&gt;
&lt;p&gt;The best way to deal with the transient nature of spot instances is to use the following workflow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write the code on your local-host&lt;/li&gt;
&lt;li&gt;Prototype the code on your local-host with a small sample of the data you want to process.&lt;/li&gt;
&lt;li&gt;Move your code to your EC2 instance and then run the code. I usually use github for this. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This way we minimize the amount of time that we have to run the EC2 instance and we don't have to worry about losing any code because it is all in the local host.&lt;/p&gt;
&lt;p&gt;If you end up writing novel code in your EC2 instance I recommend keeping your code synced with github.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Footnotes"&gt;Footnotes&lt;a class="anchor-link" href="#Footnotes"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;[1] Some commands might be different above if you choose a different AMI.&lt;/p&gt;
&lt;p&gt;[2] In the future, I recommend creating your own AMI so you don't have to do this every time.&lt;/p&gt;
&lt;p&gt;[3] For installing the apps, I recommend you use &lt;a href="https://www.continuum.io/downloads"&gt;Anaconda&lt;/a&gt; to install Python and dependencies. Note that you will have to restart your shell session in order to use&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="AWS"></category><category term="*Nix"></category></entry><entry><title>In Search of the Most Promising Movie Remakes or Sequels</title><link href="http://analyticalsen.se/blog/films_2015.html" rel="alternate"></link><published>2015-10-22T00:00:00+02:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-10-22:blog/films_2015.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Over the past couple of years Netflix and other tech firms have been enormously successful producing TV series for their subscribers. What would this strategy look like in the case of movies? I use data publicly available from Box Office Mojo and IMDB to find the films that are most likely to have a successful sequel.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Movies-vs-TV-Series"&gt;Movies vs TV Series&lt;a class="anchor-link" href="#Movies-vs-TV-Series"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;For subscription services like HBO and Netflix, focusing on series rather than movies makes intuitive sense. This is because both series and subscription services are recurring on a regular basis. Despite this intuition, history suggests that people are willing to subscribe for movies as well. HBO relied soley on movies for the first 20 years of its existence.&lt;/p&gt;
&lt;p&gt;Producing original content can also make a lot of sense. An expensive series like House of Cards costs about &lt;a href="https://www.washingtonpost.com/local/md-politics/how-did-house-of-cards-get-millions-in-maryland-tax-credits/2014/02/21/c1eb375c-9b16-11e3-975d-107dfef7b668_story.html?wpisrc=nl_buzz"&gt;60 million&lt;/a&gt; a season. Given that Netflix has &lt;a href="http://www.statista.com/statistics/250934/quarterly-number-of-netflix-streaming-subscribers-worldwide/"&gt;33.3 Million subscribers&lt;/a&gt;. Since new subscribers are going to be paying \$120 a year, Netflix only has to increase the number of their subscribers by 1.5% to break even. In the case of house of cards, it seems likely that Netflix made a good profit on the series.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[2]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;costs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="n"&gt;e6&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;subsciber_cost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
&lt;span class="n"&gt;sub_rev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subsciber_cost&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;33.3e6&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$&lt;/span&gt;&lt;span class="si"&gt;{:,}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_rev&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;0.015&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;$59,940,000
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The breakeven point for movies can be much lower. Summer blockbusters budgets may attract the most attention with their eyewatering budgets but many movies cost 25 million or less. The break-even point for a 25MM film would be to increase the subscriber base by about 0.7%.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Stylized-Facts"&gt;Stylized Facts&lt;a class="anchor-link" href="#Stylized-Facts"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;My investigation yields the following relevant results:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;The single most important factor is to be beloved by the audience.&lt;ul&gt;
&lt;li&gt;1% increase in rating of the masses associated with a 6% increase of ROI. &lt;/li&gt;
&lt;li&gt;critics unimportant. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Though Budget does a great job of predicting box office sales, it negatively correlated with ROI. &lt;ul&gt;
&lt;li&gt;A 10% increase in production budget is associated with a 5% decrease in ROI. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;High-cost films are much more unpredictable than than low-cost films&lt;/li&gt;
&lt;li&gt;Audience reviews  of the original does not predict reviews of the first&lt;/li&gt;
&lt;li&gt;Month of year is unimportant once controlling for the above except for October. &lt;/li&gt;
&lt;li&gt;Sequels have a high ROI. &lt;ul&gt;
&lt;li&gt;Gross on average 5 times their production budgets&lt;/li&gt;
&lt;li&gt;Under traditional assumptions: 278% ROI&lt;/li&gt;
&lt;li&gt;Under realistic assumptions: 112% ROI&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Strategy"&gt;Strategy&lt;a class="anchor-link" href="#Strategy"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Finding the most promising remake candidates requires understanding the movie industry better. I use ROI to measure the success of a movie because it is an excellent proxy for how many people viewed the movie.&lt;/p&gt;
&lt;p&gt;I train a linear regression model that predicts ROI based on a basket of features retrieved from IMDB and Box Office Mojo. I divide my dataset of sequels into a training set (85% of total data) and a test set (15%) of total data. I then use a linear regression with L1 normalization to find the most important factors that are correlated with ROI. My model assumes that there are no confounders ($E[\epsilon \mid X] = 0$. This is a major limitation of my model.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Important-Relationships"&gt;Important Relationships&lt;a class="anchor-link" href="#Important-Relationships"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="" alt=""&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3447.png" alt=""&gt;
&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3451.png" alt=""&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Everything-else-is-not-significant"&gt;Everything else is not significant&lt;a class="anchor-link" href="#Everything-else-is-not-significant"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;More or less every regression looks like&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/97258109/Screens/S3448.png" alt=""&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Important-Features"&gt;Important Features&lt;a class="anchor-link" href="#Important-Features"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I find that only budget, audience rating, and being realased in October have a statistically significant effect on ROI. Surprisingly, the quality or box office of the original film does not seem to influence the results. My analysis suggests that it is difficult to predict ex-ante the success of movies.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Factor&lt;/th&gt;
&lt;th&gt;Change in ROI&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Released in Month of October&lt;/td&gt;
&lt;td&gt;$\Uparrow 5\%$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\Uparrow$ Budget 10%&lt;/td&gt;
&lt;td&gt;$\Downarrow 5.2\%$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$\Uparrow$ Audience Rating 1%&lt;/td&gt;
&lt;td&gt;$\Uparrow$ 6.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Other months&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Runtime&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Genre&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Days since sequel&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Months other than October&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MPAA Rating&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Critic rating&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Change in PB from original&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Audience rating of original&lt;/td&gt;
&lt;td&gt;0*&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;* Statistically insignificantly different from 0&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="What-Kinds-of-Movies-Should-be-Remade?"&gt;What Kinds of Movies Should be Remade?&lt;a class="anchor-link" href="#What-Kinds-of-Movies-Should-be-Remade?"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;Lower risk: Focus on cheaper films&lt;ul&gt;
&lt;li&gt;Less likely to have massively negative ROI.&lt;/li&gt;
&lt;li&gt;Able to produce many cheap films rather than a few expensive films&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Release the Movie in October&lt;ul&gt;
&lt;li&gt;Unmet demand before the busy months of November/December?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Do a good job on the sequel&lt;ul&gt;
&lt;li&gt;Audience opinion on sequels not correlated with the rating of the original film.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Keep it short&lt;ul&gt;
&lt;li&gt;Runtime not associated with ROI.&lt;/li&gt;
&lt;li&gt;Do not take this logic too far. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="The-Most-Promising-Sequels"&gt;The Most Promising Sequels&lt;a class="anchor-link" href="#The-Most-Promising-Sequels"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Keeping the above in mind, these are the films that have the best chance to suceed. As many films (~200) satisfy all 4 conditions above, films are ranked by their thumb-rule ROI.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;Gone with the wind&lt;/li&gt;
&lt;li&gt;Juno&lt;/li&gt;
&lt;li&gt;Crocodile Dundee&lt;/li&gt;
&lt;li&gt;Blair Witch Project&lt;/li&gt;
&lt;li&gt;The Rocky Horror Picture show&lt;/li&gt;
&lt;li&gt;National Lamboon's Animal House&lt;/li&gt;
&lt;li&gt;Platoon&lt;/li&gt;
&lt;li&gt;Fahrenheit 9/11&lt;/li&gt;
&lt;li&gt;Magic Mike&lt;/li&gt;
&lt;li&gt;The Usual Suspects. &lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Appendix"&gt;Appendix&lt;a class="anchor-link" href="#Appendix"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;See the appendix and accompanying code &lt;a href="https://github.com/Will-So/films"&gt;here&lt;/a&gt;. The appendix contains information like how I computed ROI as well as various limitations of the model and more descriptive statistics.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="DS"></category></entry><entry><title>Quickly Make CLI Tools with Python</title><link href="http://analyticalsen.se/blog/Quickly_Make_CLI_Tools_with_Python.html" rel="alternate"></link><published>2015-10-21T00:00:00+02:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-10-21:blog/Quickly_Make_CLI_Tools_with_Python.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Synopsis"&gt;Synopsis&lt;a class="anchor-link" href="#Synopsis"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;If thinking of making a CLI tool, consider using Python with &lt;code&gt;click&lt;/code&gt;. It is very fast and will make your life easier. It is probably the most straightforward way to automate tasks.&lt;/p&gt;
&lt;p&gt;This script removes an enormous headache of making blog posts. As I already tend to take notes using the Jupyter Notebook, it makes it very easy to blog regularly.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Which-Library-to-Use"&gt;Which Library to Use&lt;a class="anchor-link" href="#Which-Library-to-Use"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;There are a number of good libraries that make making CLI apps with Python easy. I am personally a big fan of &lt;code&gt;click&lt;/code&gt; as it seems to be the quickest way to get running. I have a short CLI available that automates my blog posting workflow &lt;a href="https://github.com/Will-So/pelican_autpost"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here is the heart of &lt;code&gt;pelican_autopost&lt;/code&gt;. This little code already makes all of the necessary documentation, prompts, default values, and arguments.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[3]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;click&lt;/span&gt;
&lt;span class="n"&gt;BLOG_DIR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;~/blog&amp;#39;&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;command&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;--blog-dir&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;BLOG_DIR&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;--notebook-path&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Enter the full notebook path&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;files must be&amp;#39;&amp;#39;located in `blog_dir`&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;--title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;enter the title. Must be unique&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;--tags&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;enter a tag. You may enter more than one via&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="n"&gt;multiple&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nd"&gt;@click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;--category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blog_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;notebook_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;category&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Simple program that takes the directory of a notebook&lt;/span&gt;
&lt;span class="sd"&gt;     (use `greadlink -f file.ipynb |  pbcopy`)&lt;/span&gt;
&lt;span class="sd"&gt;    and other parameters and then publishes it to my pelican blog.&lt;/span&gt;


&lt;span class="sd"&gt;    Examples&lt;/span&gt;
&lt;span class="sd"&gt;    ----&lt;/span&gt;
&lt;span class="sd"&gt;    ./pelican_auto_post.py --tags *Nix --tags CLI  --title sqlite3&lt;/span&gt;
&lt;span class="sd"&gt;    Enter the full notebook path: /Users/Will/Devel/blog_posts/sqlite3_CLI.ipynb&lt;/span&gt;

&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;splitext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;notebook_path&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;make_md&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blog_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;category&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;notebook_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;copy_notebook&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;notebook_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blog_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;publish&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blog_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Running-the-Script-from-anywhere"&gt;Running the Script from anywhere&lt;a class="anchor-link" href="#Running-the-Script-from-anywhere"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now that we have the script, we can easily run it from anywhere by performing the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Make a directory for all of your CLI tools if you don't already have it. I use &lt;code&gt;~/scipts&lt;/code&gt;. Move your script to here.&lt;/li&gt;
&lt;li&gt;Add this directory to your &lt;code&gt;PATH&lt;/code&gt; environmental variable. For OSX this is &lt;code&gt;~/.bash_profile&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;Make sure you have the proper shebang line added to the top of your file &lt;code&gt;#!/usr/bin/env python3&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Executing-Bash-Scripts"&gt;Executing Bash Scripts&lt;a class="anchor-link" href="#Executing-Bash-Scripts"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Executing bash scripts from Python can be tricky. The &lt;a href="https://github.com/Will-So/pelican_autpost"&gt;Github&lt;/a&gt; describes how I did it but the most robust way to do this seems to be to execute the data directly from python like this:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;~/scripts/script_name.sh&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;rc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Make sure that you only run this with trusted code that oyu are feeding it yourself. Otherwise it poses a security issue. An alterantive option would be to santize the file in Python before using &lt;code&gt;subprocess.call&lt;/code&gt; on it.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Testing"&gt;Testing&lt;a class="anchor-link" href="#Testing"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;If the CLI is quite small, often times the best test is just going to be the script itself. I recommend to only test to prevent the things that can cause problems (accidently overwriting or deleting files). In the pelican autopost tool, for example, the only test I feel helped is the one that insures that the markdown files won't be overwritten because this could cause problems if there were to be two blog posts of the same title.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/p&gt;</summary><category term="Python"></category><category term="CLI"></category></entry><entry><title>sqlite3</title><link href="http://analyticalsen.se/blog/sqlite3.html" rel="alternate"></link><published>2015-07-25T00:00:00+02:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-07-25:blog/sqlite3.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="What-is-sqlite3-good-for?"&gt;What is sqlite3 good for?&lt;a class="anchor-link" href="#What-is-sqlite3-good-for?"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Using the &lt;code&gt;sqlite3&lt;/code&gt; CLI can often be a good alternative to python-based solutions when the operations we are performing is easy to express directly with SQL.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="How-does-it-work?"&gt;How does it work?&lt;a class="anchor-link" href="#How-does-it-work?"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;Commands like &lt;code&gt;.tables&lt;/code&gt; are prefixed with a dot. &lt;/li&gt;
&lt;li&gt;SQL statements &lt;code&gt;select * from AllstarFull&lt;/code&gt; end with a semicolon&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Useful commands are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;.tables&lt;/code&gt;: Shows all tables in the db.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.timer ON&lt;/code&gt;: times how long an operation takes between &lt;code&gt;.timer ON&lt;/code&gt; and &lt;code&gt;.timer OFF&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.schema&lt;/code&gt; shows the schema of all the tables in the db&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Cookbook"&gt;Cookbook&lt;a class="anchor-link" href="#Cookbook"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We can dump files to csv via the following syntax&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;mode&lt;/span&gt; &lt;span class="n"&gt;CSV&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;output&lt;/span&gt; &lt;span class="k"&gt;table&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can run an SQL script from the command line using the following syntax&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sqlite3 database.db &amp;lt; sql_script.sql&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After dropping a table, you may have to use &lt;code&gt;VACUUM;&lt;/code&gt; to reclaim the space that the dropped table was using.&lt;/p&gt;
&lt;h2 id="Dealing-with-Database-or-Disk-is-Full"&gt;Dealing with Database or Disk is Full&lt;a class="anchor-link" href="#Dealing-with-Database-or-Disk-is-Full"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When dealing with tables that are large compared to the space on disk it's possible to get an error that says: &lt;code&gt;Error: near line 41: database or disk is full&lt;/code&gt; even though the disk isn't full and even though the database is far smaller than the 120TB size limit.&lt;/p&gt;
&lt;p&gt;This could be because either 1) the temporary file directory is filling up or 2) the database is corrupted.&lt;/p&gt;
&lt;p&gt;In the case of (1), the solution is either to tell SQLite to put everything in ram via &lt;code&gt;sqlite&amp;gt; prgrama temp_store = 2;&lt;/code&gt;. If you don't have enough ran for the operation, you can change the temporary directory with the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sqlite&amp;gt; pragma temp_store = 1;
sqlite&amp;gt; pragma temp_store_directory = '/spacious/hdd/data';&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the case of (2) hope is still not lost. Search the internet for ways to repair a corrupt SQLite database.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="When-to-use-SQLITE"&gt;When to use SQLITE&lt;a class="anchor-link" href="#When-to-use-SQLITE"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;SQLite is much easier to work with than other RBDMS because it is serverless, requires few external libraries, and requires no configuration.&lt;/p&gt;
&lt;p&gt;I think of SQLite as being the Python of databases. If you are using an RBDMS for a project, you should have a good reason not to use SQLite. On websites it can handle 100k hits/day with ease and &lt;a href="https://www.sqlite.org/whentouse.html"&gt;500k is probably a more realistic upper bound&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;SQLite&lt;/code&gt; &lt;a href="https://www.sqlite.org/whentouse.html"&gt;website&lt;/a&gt; offers a few cases when SQLite probably is not the best choice.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If your DB is so big that it can't fit on a single disk, then you probably need something else.&lt;/li&gt;
&lt;li&gt;Websites with very high write volumes&lt;/li&gt;
&lt;li&gt;Multiple uers need to write to a db simultaneously. &lt;/li&gt;
&lt;li&gt;You aren't storing your RBDMS on the same hard drive as your app.&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="('*Nix'"></category><category term="'CLI')"></category></entry><entry><title>WC CLI Quick Reference Part 1</title><link href="http://analyticalsen.se/blog/WCCLI.html" rel="alternate"></link><published>2015-06-20T00:00:00+02:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2015-06-20:blog/WCCLI.html</id><summary type="html">&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="What-is-WC-good-for?"&gt;What is WC good for?&lt;a class="anchor-link" href="#What-is-WC-good-for?"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;wc&lt;/code&gt; is available by default on my *nix machines. It is useful to determine the following about a file:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The number of words or characters in a file.&lt;/li&gt;
&lt;li&gt;The number of columns in a file&lt;/li&gt;
&lt;li&gt;the number of lines in a file&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Examples"&gt;Examples&lt;a class="anchor-link" href="#Examples"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;wc -l newdataset.csv&lt;/code&gt; Returns the number of lines in &lt;code&gt;newdataset.csv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wc -w masterthesis.txt&lt;/code&gt; returns the number of words&lt;/li&gt;
&lt;li&gt;&lt;code&gt;head -1 newdataset.csv | wc -w&lt;/code&gt; returns the number of columns in a file &lt;strong&gt;IF&lt;/strong&gt; every column name is only 1 word. This is usually the case with &lt;code&gt;csv&lt;/code&gt; files and virtually always the case with &lt;code&gt;tsv&lt;/code&gt; files. Run just the first command first to verify that this is the case.&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="*Nix"></category><category term="CLI"></category></entry><entry><title>license</title><link href="http://analyticalsen.se/blog/license.html" rel="alternate"></link><published>2012-12-01T10:02:00+01:00</published><author><name>Will Sorenson</name></author><id>tag:analyticalsen.se,2012-12-01:blog/license.html</id><summary type="html">&lt;p&gt;The MIT License (MIT)&lt;/p&gt;
&lt;p&gt;Copyright (c) 2014 Daan Debie&lt;/p&gt;
&lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:&lt;/p&gt;
&lt;p&gt;The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.&lt;/p&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.&lt;/p&gt;</summary></entry></feed>